hosts = [
  {
    url = "https://ef-magazin.de/"
    path = "?page="
    pageTo = 2
    pageTo = ${?FFF_EFMAGAZIN_PAGE_TO}
    publisher = "EFMAGAZIN"
  },
  {
    url = "https://freiheitsfunken.info/"
    path = "?page="
    pageTo = 2
    pageTo = ${?FFF_FREIHEITSFUNKEN_PAGE_TO}
    publisher = "FREIHEITSFUNKEN"
  },
  {
    url = "https://www.misesde.org/"
    path = "?_page="
    pageTo = 1
    pageTo = ${?FFF_MISESDE_PAGE_TO}
    publisher = "MISESDE"
  },
  {
    url = "https://schweizermonat.ch/"
    path = "archivperlen/, dossiers/, kolumnen/, schwerpunkte/"
    pageTo = 0
    publisher = "SCHWEIZER_MONAT"
  }
]

databaseConfig {
  # jdbc:postgresql://0.0.0.0:5432/rss_feeds
  url = "/<yourpath>"
  url = ${?FFF_DB_URL}
  username = ${?FFF_DB_USERNAME}
  password = ${?FFF_DB_PASSWORD}
}

# how many elements will scrape in the same time of multiple chunks, parallel
scrapeConcurrency = 4
scrapeConcurrency = ${?FFF_CONCURRENCY}

update = "11:34" # UTC
update = ${?FFF_UPDATE_TIME}

updateInterval = 24 # hours
updateInterval = ${?FFF_UPDATE_INTERVAL} # hours

# initial load of first scraped elements
initialReverse = false
initialReverse = ${?FFF_INITIAL_REVERSE} # hours

pageSize = 50 # elements per page
pageSize = ${?FFF_PAGE_SIZE}
